<!DOCTYPE html>
<html>
<head>
    <title>EECS 7700  - Schedule</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" title="style1">
    <!-- <link rel="icon" type="image/ico" href="images/favicon.ico"> -->
    <!-- <link href='https://fonts.googleapis.com/css?family=Open+Sans:400' rel='stylesheet' type='text/css'> -->
</head>
<body>

    <ul id="nav">
	    <li><a href="index.html">Home</a></li>
	    <li><a href="schedule.html">Schedule</a></li>
	    <li><a style="color:#232C2D; background:#FFFFFF" href="presentation.html">Presentation</a></li>
	</ul>
    

    <div id="all">
        

        <div id="intro">
            <table width = "100%">
                <!-- <tr>
                    <td>
                        <p align="left" style="font-size:22px">
                            <b>EE/CSC 7700 - Fall 2024 Paper Presentations<br></b>
                        </p>
                        
                        
                    </td>
                </tr> -->

                <tr>
                    <td>
                        <p align="left" style="font-size:18px; background-color: lightblue;">
                            <b>Week 13: Knowledge Integration<br></b>
                        </p>
                        <p>
                            <b>Reading tasks </b> <br>
                            
                            A Semantic Loss Function for Deep Learning with Symbolic Knowledge [<a href="https://arxiv.org/abs/1711.11157" target="_blank"> Link </a>]<br>
                            SpecGuard: Specification Aware Recovery for Robotic Autonomous Vehicles from Physical Attacks  [<a href="https://www.dropbox.com/scl/fi/bw1itoqi03xwe3preeoma/CCS_2024_SpecGuard_Pritam.pdf?rlkey=t0qgyssuaac7ntyzhqfbjjrn2&e=1&st=yy6xv8xf&dl=0" target="_blank"> Link </a>]<br>
                            Informed Machine Learning - A Taxonomy and Survey of Integrating Prior Knowledge into Learning Systems [<a href="https://ieeexplore.ieee.org/abstract/document/9429985" target="_blank"> Link </a>]<br>
                        </p>

                        <!-- <p>
                            <b>Blog Post 19: Semantic Losss</b> <br>
                            
                            This paper discusses a method of improving the integration of symbolic logic into a neural network loss function by factoring in an additional "semantic loss function" without modifying the actual model or dataset(s) utilized. The utility of symbolic knowledge is that it improves user interpratability in the loss function without sacrificing too much accuracy, but as neural networks tend to struggle with this information being directly provided, this paper's approach helps alleviate that issue. The concept of semantic loss is described along with explanations of the experimentation on data for semi-supervised classification, as well as more complex scenarios involving reasoning.
                            [<a href="./presentations/BP19/blogpost.html" target="_blank">Read more ...</a>]<br>
                        </p> -->
                 
                        <p align="left" style="font-size:18px; background-color: lightblue;">
                            <b>Week 12: ML Interpretebility<br></b>
                        </p>
                        <p>
                            <b>Reading tasks </b> <br>                         
                            A Survey for Machine Learning Security to Securing Machine Learning for CPS [<a href="https://ieeexplore.ieee.org/document/9252851" target="_blank"> Link </a>]<br>
                            Asymmetry Vulnerability and Physical Attacks on Online Map Construction for Autonomous Driving  [<a href="https://arxiv.org/abs/2509.06071" target="_blank"> Link </a>]<br>
                        </p>
                        
                   
                        <p align="left" style="font-size:18px; background-color: lightblue;">
                            <b>Week 11: Reinforcement Learning<br></b>
                        </p>
                        <p>
                            <b>Reading tasks </b> <br>
                            
                            Mastering the game of Go with deep neural networks and tree search  [<a href="https://www.nature.com/articles/nature16961" target="_blank"> Link </a>]<br>
                            Adversarial Policies: Attacking Deep Reinforcement Learning  [<a href="https://openreview.net/pdf?id=HJgEMpVFwB" target="_blank"> Link </a>]<br>
                        </p>




                        <p align="left" style="font-size:18px; background-color: lightblue;">
                            <b>Week 9: Adversarial ML<br></b>
                        </p>
                        <p>
                            <b>Reading tasks </b> <br>
                            
                            L-HAWK: A Controllable Physical Adversarial Patch Against a Long-Distance Target  [<a href="https://www.ndss-symposium.org/wp-content/uploads/2025-26-paper.pdf" target="_blank"> Link </a>]<br>
                            Generative Adversarial Nets [<a href="https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf" target="_blank"> Link </a>]<br>
                        </p>
                        <!-- <p>
                            <b>Blog Post 14: GANs</b> <br>
                            
                            The authors of this paper present their innovative Generative Adversarial Nets, or GANs.  This process utilizes adversarial training by training two models simultaneously- one generative model and one discriminative model.  These models achieve different goals that when used together, are able generate "synthetic" output that is similar to real data.
                            [<a href="./presentations/p14/blog.html" target="_blank">Read more ...</a>]<br>
                        </p> -->
                        
                                                
         

                        
                        <p align="left" style="font-size:18px; background-color: lightblue;">
                            <b>Week 8: Safety Monitoring in CPS<br></b>
                        </p>
                        <p>
                            <b>Reading tasks </b> <br>                           
                            Attacks against process control systems: risk assessment, detection, and response [<a href="https://dl.acm.org/doi/abs/10.1145/1966913.1966959" target="_blank"> Link </a>]<br>
                            Recovery-Guaranteed Sensor Attack Detection for Cyber-Physical Systems [<a href="https://ieeexplore.ieee.org/abstract/document/11018669" target="_blank"> Link </a>]<br>
                        </p>




                        <p align="left" style="font-size:18px; background-color: lightblue;">
                            <b>Examples: Machine Learning Applications<br></b>
                        </p>
                        <p>
                            <b>Reading tasks </b> <br>
                            
                            Deep Residual Learning for Image Recognition [<a href="https://arxiv.org/abs/1512.03385" target="_blank"> Link </a>]<br>
                            Attention Is All You Need [<a href="https://arxiv.org/abs/1706.03762" target="_blank"> Link </a>]<br>
                        </p>

        
                        <p>
                            <b>Blog Post 2: Transformer </b> <br>
                            This paper introduces a novel sequence transduction model architecture named the Transformer. 
                            This architecture is based solely on attention mechanisms, eliminating the need for recursion and convolution. 
                            The model addresses the limitations of sequence models that rely on recursive processes, which perform poorly in parallelization and computational efficiency for longer sequences.
                            The Transformer adopts an encoder-decoder structure, where the encoder consists of identical layers with multi-head self-attention and fully connected feed-forward networks, 
                            while the decoder mirrors this structure but adds a multi-head attention layer on the encoder's output; utilizing scaled dot-product attention and multi-head attention, 
                            the model computes the importance of key-value pairs based on queries and allows joint attention across different subspaces, 
                            with encoder-decoder attention enabling the decoder to focus on all input positions, 
                            self-attention improving contextual understanding by attending to all positions within layers, 
                            and positional encodings ensuring the model captures the order of tokens in a sequence.
                            [<a href="./Fall 2024/presentations/p2/final.html" target="_blank">Read more ...</a>]<br>
                        </p>

                        <p>
                            <b>Blog Post 1: ResNet </b> <br>
                            As the number of layers of neural networks increases, the problems of overfitting, gradient vanishing, and gradient explosion often occur, so this article came into being. In this paper, the concept of deep residual networks (ResNets) is proposed. By introducing "shortcut connections," this study solves the problem of gradient vanishing in deep network training and has an important impact on the field of deep learning. The method of the paper explicitly redefines the network layers as learning residual functions relative to the inputs. By learning residuals, the network can be optimized more easily and can train deeper models more efficiently. Therefore, this method can help solve the performance degradation problem that may occur when the network layer increases. In addition, the article displays the experimental part. The model shows significant improvements in handling large-scale visual recognition tasks like ImageNet and CIFAR-10. The application of deep residual networks in major visual recognition competitions like ILSVRC and COCO 2015 further proves their power and wide applicability.
                            [<a href="./Fall 2024/presentations/p1/final.html" target="_blank">Read more ...</a>]<br>
                        </p>
                        <!-- <p align="right" style="font-size:18px">
                         <a href="./presentations/p1/final.html" target="_blank"> Read more ... </a><br>
                        </p> -->
                        
                        
                    </td>
                </tr>

            </table>
        </div>
        <br>
        <br>
    </div>


    <!-- <hr> -->
    </br>

  

</body>
</html>